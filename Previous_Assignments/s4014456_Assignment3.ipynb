{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Analysis\n",
    "\n",
    "The goal of this assignment is to write a first version of an an interactive QA system. The system should be able to take a question in natural language (English) as input, analyse the question, and generate a SPARQL query for it.\n",
    "\n",
    "For now, we will restrict our attention to questions of the form\n",
    "\n",
    "Who/What was/is/were (the) X of Y? \n",
    "\n",
    "i.e.\n",
    "\n",
    "* What are the genres of Inception?\n",
    "* What are the main subjects of Saving Private Ryan?\n",
    "* What are the names of the Coen Brothers?\n",
    "* What is the box office of Interstellar?\n",
    "* What is the country of origin of Black Mirror?\n",
    "* What is the duration of I Am Legend?\n",
    "* What is the main subject of \"The Godfather\"?\n",
    "* Who are the founders of Pixar Animation Studios?\n",
    "* Who is the composer of Lord of The Rings?\n",
    "* etc\n",
    "\n",
    "## Interactivity\n",
    "\n",
    "In a notebook, you can ask for user input by using the input function, as shown below. The text entered by the user is stored in the variable question. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please ask a question\n",
      "gjkh\n"
     ]
    }
   ],
   "source": [
    "question = input('Please ask a question\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linguistic Analysis with Spacy\n",
    "\n",
    "To generate a SPARQL query, the system needs to find a a property and an entity. The first step is to match the correct words in the question. So, for the first example, the property is indicated by the word _genres_ and the entity by the word _Inception_ These words can be sent as key-words to a wikidata api, to find the corresponding wikidata IDs (URIs). (More on this below)\n",
    "\n",
    "Pattern matching can be done using regular expressions (using the re python library). Alternatively, we can use a Spacy, a toolkit for doing linguistic analysis.\n",
    "\n",
    "[Spacy](https://spacy.io/usage) is a toolkit that comes with pretrained models for doing linguistic analysis in a number of languages. It can read in a text or sentence, tokenize the text (separate punctuation from words), assign Part-of-Speech (NOUN, VERB, PROPN, etc.) to tokens, lemmatize words (_actors_ --> _actor_), and detect named entities (like movie titles). See here for a short [tutorial](https://spacy.io/usage/spacy-101). \n",
    "\n",
    "When you install Spacy, make sure to also download the statistical model for analysing English sentences, en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"en_core_web_sm\") # this loads the model for analysing English text\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy tokenization and annotation\n",
    "\n",
    "The Spacy nlp function analyses an input text (i.e. the question of the user), and assigns an annotation to each token in the input. It returns a list of token objects, where each token object is a dictionary that has values for various attributes of each token in the sentence. \n",
    "\n",
    "The example below illustrates how to iterate over the token objects, and find interesting attributes. Spans can be useful if you want to grab multiple tokens. The analyzer also finds names of entities (persons, organisations, locations), but, unfortunately, for movie titles this often does not work. A more robust approach might be to find tokens that start with an uppercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who who PRON\n",
      "are be AUX\n",
      "the the DET\n",
      "main main ADJ\n",
      "characters character NOUN\n",
      "of of ADP\n",
      "the the DET\n",
      "movie movie NOUN\n",
      "Apocalypse apocalypse NOUN\n",
      "Now now ADV\n",
      "? ? PUNCT\n",
      "---------------\n",
      "main characters\n",
      "---------------\n",
      "Apocalypse Now LAW\n",
      "---------------\n",
      "Who\n",
      "Apocalypse\n",
      "Now\n",
      "---------------\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "question = 'Who are the main characters of the movie Apocalypse Now?'\n",
    "\n",
    "parse = nlp(question) # parse the input \n",
    "\n",
    "for word in parse : # iterate over the token objects \n",
    "    print(word.text, word.lemma_, word.pos_)\n",
    "print('---------------')\n",
    "print(parse[3:5].text) # you can also select multiple tokens as a span. \n",
    "print('---------------')\n",
    "\n",
    "for ent in parse.ents : # the analysis also detects names of entities. Very unreliable for movie titles...\n",
    "    print(ent.text, ent.label_)\n",
    "    \n",
    "print('---------------')\n",
    "for word in parse :\n",
    "        if word.text.istitle() : # check if word starts with uppercase letter \n",
    "            print(word)\n",
    "print('---------------')\n",
    "print(parse[8:10].text.istitle()) # check if all words in a span start with uppercase  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "\n",
    "For a quick understanding of what the parser does, and how it assigns part-of-speech, entities, etc. you can also visualise parse results. Below, the entity visualiser and parsing visualiser is demonstrated. You can ignore the arrows (dependency links) for now, we return to them next week. \n",
    "\n",
    "This code is for illustration only, it is not part of the assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Who is the main character of the movie \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Harry Potter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"3f1e27bc98004c20ba4aeae7111e1d61-0\" class=\"displacy\" width=\"1800\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Who</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">main</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">character</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">movie</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">Harry</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">Potter</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-1\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-2\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-3\" stroke-width=\"2px\" d=\"M245,352.0 C245,89.5 745.0,89.5 745.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,354.0 L753.0,342.0 737.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-4\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910.0,354.0 L918.0,342.0 902.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-6\" stroke-width=\"2px\" d=\"M945,352.0 C945,177.0 1265.0,177.0 1265.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1265.0,354.0 L1273.0,342.0 1257.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-7\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,354.0 L1462,342.0 1478,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-8\" stroke-width=\"2px\" d=\"M245,352.0 C245,2.0 1625.0,2.0 1625.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-3f1e27bc98004c20ba4aeae7111e1d61-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1625.0,354.0 L1633.0,342.0 1617.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "question = \"Who is the main character of the movie Harry Potter\"\n",
    "\n",
    "parse = nlp(question)\n",
    "\n",
    "displacy.render(parse, jupyter=True, style=\"ent\")\n",
    "\n",
    "displacy.render(parse, jupyter=True, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the Wikidata entity finder \n",
    "\n",
    "From the parse of the user question, you can extract the words for the property and the entity that are needed to formulate a SPARQL query. The ids of the property and entity can be found by accessing the wikidata entity finder.\n",
    "\n",
    "See the example below for finding the id of the movie The Godfather. In most cases, the first result is correct, but it may be necessary to try various ids...\n",
    "\n",
    "Properties can be found by including 'type' : 'property' in the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q47703\tThe Godfather\t1972 American film directed by Francis Ford Coppola\n",
      "Q243556\tThe Godfather\t1969 novel by Mario Puzo\n",
      "Q1139696\tThe Godfather\t2006 open world action-adventure video game\n",
      "Q443678\tNikola Peković\tMontenegrin basketball player\n",
      "Q1066512\tCharles Wright\tAmerican professional wrestler\n",
      "Q1158135\tThe Godfather\tsoundtrack of the 1972 crime film of the same name\n",
      "Q4051101\tThe Godfather\t1991 video game based on the Godfather movie trilogy\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://www.wikidata.org/w/api.php'\n",
    "params = {'action':'wbsearchentities', \n",
    "          'language':'en',\n",
    "          'format':'json'}\n",
    "\n",
    "params['search'] = 'The Godfather'\n",
    "json = requests.get(url,params).json()\n",
    "for result in json['search']:\n",
    "    print(\"{}\\t{}\\t{}\".format(result['id'], result['label'], result['description']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a SPARQL query \n",
    "\n",
    "With the id of the property and the entity, an SPARQL query can be formulated, and the sparql endpoint of wikidata can be queried for an answer. Note that this is the same as in the previous assignment.\n",
    "\n",
    "Also note that for python, a SPARQL query is just a string, so you can construct the query by concatenating the start of the query, the ids, and the end of the query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT ?answerLabel WHERE { wd:q47703 wdt:p577....\n"
     ]
    }
   ],
   "source": [
    "ID1 = 'q47703'\n",
    "ID2 = 'p577'\n",
    "query = 'SELECT ?answerLabel WHERE { wd:' + ID1 + ' wdt:' + ID2 + '....'\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment \n",
    "\n",
    "Using the steps outlined above, write a function that takes input from the user, analyses it with Spacy, extracts the relevant key-words, finds the wikidata URIs for these, and sends the SPARQL query to the sparql endpoint, and prints the answer. \n",
    "\n",
    "Include 10 examples of questions that worked for your system in the comments or in a separate markdown cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://www.wikidata.org/w/api.php'\n",
    "url1 = 'https://query.wikidata.org/sparql'\n",
    "\n",
    "params1 = {'action':'wbsearchentities', \n",
    "          'language':'en',\n",
    "          'format':'json'} #for entities\n",
    "params2 = {'action':'wbsearchentities', \n",
    "          'language':'en',\n",
    "          'format':'json',\n",
    "          'type':'property'} #for properties\n",
    "\n",
    "words = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_entity(question):\n",
    "    parse = nlp(question)\n",
    "    label = [\"WORK_OF_ART\", \"PERSON\", \"ORG\", \"NOUN\"]\n",
    "    for entity in parse.ents: #getting entities which have the correct labels eg work of art i.e. a movie\n",
    "        if entity.label_ in label:\n",
    "            return entity.text\n",
    "\n",
    "def process_property(text):\n",
    "        pos = [\"NOUN\", \"ADP\"] #all properties have a noun eg duration or main subject\n",
    "        tokens = nlp(text)\n",
    "        return ' '.join(token.lemma_ for token in tokens if token.pos_ in pos).rstrip('of ') \n",
    "        #in cases like country of origin of remove the of at end\n",
    "        #get the lemma i.e. the simplest version of the token \n",
    "        \n",
    "def entities(entity):\n",
    "    ids = []\n",
    "    params1['search'] = entity\n",
    "    json = requests.get(url,params1).json()\n",
    "    for result in json['search']:\n",
    "        ids.append(format(result['id'])) #getting all the relevant entity IDs\n",
    "    return ids\n",
    "\n",
    "def properties(property1):\n",
    "    ids = []\n",
    "    params2['search'] = property1\n",
    "    json = requests.get(url,params2).json()\n",
    "    for result in json['search']:\n",
    "        ids.append(format(result['id'])) #getting all relevant property IDs\n",
    "    return ids\n",
    "\n",
    "def query(ID1, ID2):\n",
    "    query = 'SELECT ?answerLabel WHERE { wd:' + str(ID1) + \" wdt:\" + str(ID2) + ' ?answer .SERVICE wikibase:label {bd:serviceParam wikibase:language \"en\" .}}'\n",
    "    results = requests.get(url1, params={'query': query, 'format': 'json'}).json()\n",
    "    return results\n",
    "\n",
    "def question_answer(question):\n",
    "    propertyy = process_property(question)\n",
    "    entity = get_entity(question)\n",
    "    ID1 = entities(entity)\n",
    "    ID2 = properties(propertyy)\n",
    "    count = 0 \n",
    "    \n",
    "    for i in ID1:\n",
    "        for j in ID2:\n",
    "            results = query(i,j)\n",
    "            if(results is not None):\n",
    "                for item in results['results']['bindings']:\n",
    "                    for var in item :\n",
    "                        count += 1 #result was obtained so next loop don't print any more results\n",
    "                        print('{}\\t{}'.format(var,item[var]['value']))   \n",
    "            if(count >= 1):\n",
    "                return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "1) What is the duration of \"Attack of the Clones\"?\n",
    "\n",
    "2) What is the box office of Interstellar?\n",
    "\n",
    "3) What is the country of origin of Black Mirror?\n",
    "\n",
    "4) Who are the founders of Pixar Animation Studios?\n",
    "\n",
    "5) What is the main subject of \"The Godfather?\"\n",
    "\n",
    "6) Who is the director of Pulp Fiction?\n",
    "\n",
    "7) Who are the cast members of Titanic?\n",
    "\n",
    "8) What is/are the publication dates of Avatar\n",
    "\n",
    "9) What is the country of citizenship of Brad Pitt?\n",
    "\n",
    "10) What is the date of birth of Christopher Nolan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'search'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-70265da253fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mq1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'What is the duration of Attack of the Clones?'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mquestion_answer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-516d0673ef4a>\u001b[0m in \u001b[0;36mquestion_answer\u001b[1;34m(question)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mpropertyy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_property\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mentity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_entity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mID1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mID2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mproperties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpropertyy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-516d0673ef4a>\u001b[0m in \u001b[0;36mentities\u001b[1;34m(entity)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mparams1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'search'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mjson\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparams1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'search'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#getting all the relevant entity IDs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'search'"
     ]
    }
   ],
   "source": [
    "q1 = 'What is the duration of Attack of the Clones?'\n",
    "question_answer(q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = 'What is the box office of Interstellar?'\n",
    "question_answer(q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = 'What is the country of origin of Black Mirror?'\n",
    "question_answer(q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q4 = 'Who are the founders of Pixar Animation Studios?'\n",
    "question_answer(q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q5 = 'What is the main subject of \"The Godfather?\"'\n",
    "question_answer(q5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6 = 'Who is the director of Pulp Fiction?'\n",
    "question_answer(q6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q7 = 'Who are the cast members of Titanic?'\n",
    "question_answer(q7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q8 = 'What is/are the publication dates of Avatar?'\n",
    "question_answer(q8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q9 = \"What is the country of citizenship of Brad Pitt?\"\n",
    "question_answer(q9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q10 = \"What is the date of birth of Christopher Nolan?\"\n",
    "question_answer(q10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
