{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Question Analysis\n",
    "\n",
    "The goal of this assignment is to write a more flexible version of the interactive QA system. As in the previous assignment, the system should be able to take a question in natural language (English) as input, analyse the question, and generate a SPARQL query for it.\n",
    "\n",
    "## Assignment  // Additional requirements\n",
    "\n",
    "* Make sure that your system can analyse at least two more question types. E.g. questions that start with *which*, *when*, where the property is expressed by a verb, etc.\n",
    "* Apart from the techniques introduced last week (matching tokens on the basis of their lemma or part-of-speech), also include at least one pattern where you use the dependency relations to find the relevant property or entity in the question. \n",
    "* Include 10 examples of questions that your system can handle, and that illustrate the fact that you cover additional question types\n",
    "\n",
    "## Examples\n",
    "\n",
    "Here is a non-representative list of questios and question types to consider. See the list with all questions for more examples\n",
    "\n",
    "* For what movie did Leonardo DiCaprio win an Oscar?\n",
    "* How long is Pulp Fiction?\n",
    "* How many episodes does Twin Peaks have?\n",
    "* In what capital was the film The Fault in Our Stars, filmed?\n",
    "* In what year was The Matrix released?\n",
    "* When did Alan Rickman die?\n",
    "* Where was Morgan Freeman born?\n",
    "* Which actor played Aragorn in Lord of the Rings?\n",
    "* Which actors played the role of James Bond\n",
    "* Who directed The Shawshank Redemption?\n",
    "* Which movies are directed by Alice Wu?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") # this loads the model for analysing English text\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency Analysis with Spacy\n",
    "\n",
    "All the functionality of Spacy, as in the last assignment, is still available for doing question analysis. \n",
    "\n",
    "In addition, also use the dependency relations assigned by spacy. Note that a dependency relation is a directed, labeled, arc between two tokens in the input. In the example below, the system detects that *movie* is the subject of the passive sentence (with label nsubjpass), and that the head of which this subject is a dependent is the word *are* with lemma *be*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which DET det movie\n",
      "movie NOUN nsubjpass direct\n",
      "be AUX auxpass direct\n",
      "direct VERB ROOT direct\n",
      "by ADP agent direct\n",
      "Alice PROPN compound Wu\n",
      "Wu PROPN pobj by\n",
      "? PUNCT punct direct\n"
     ]
    }
   ],
   "source": [
    "question = 'Which movies are directed by Alice Wu?'\n",
    "\n",
    "parse = nlp(question) # parse the input \n",
    "\n",
    "for word in parse : # iterate over the token objects \n",
    "    print(word.lemma_, word.pos_, word.dep_, word.head.lemma_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phrases\n",
    "\n",
    "You can also match with the full phrase that is the subject of the sentence, or any other dependency relation, using the subtree function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which movies\n",
      "by Alice Wu\n"
     ]
    }
   ],
   "source": [
    "def phrase(word) :\n",
    "    children = []\n",
    "    for child in word.subtree :\n",
    "        children.append(child.text)\n",
    "    return \" \".join(children)\n",
    "        \n",
    "for word in parse:\n",
    "    if word.dep_ == 'nsubjpass' or word.dep_ == 'agent' :\n",
    "        phrase_text = phrase(word)\n",
    "        print(phrase_text)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "\n",
    "For a quick understanding of what the parser does, and how it assigns part-of-speech, entities, etc. you can also visualise parse results. Below, the entity visualiser and parsing visualiser is demonstrated. \n",
    "This code is for illustration only, it is not part of the assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Which parts does a film have?</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c9b3f1cba08e4b07afa60af279d8c5ad-0\" class=\"displacy\" width=\"1100\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Which</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">parts</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">does</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">film</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">have?</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c9b3f1cba08e4b07afa60af279d8c5ad-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c9b3f1cba08e4b07afa60af279d8c5ad-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c9b3f1cba08e4b07afa60af279d8c5ad-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c9b3f1cba08e4b07afa60af279d8c5ad-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c9b3f1cba08e4b07afa60af279d8c5ad-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c9b3f1cba08e4b07afa60af279d8c5ad-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c9b3f1cba08e4b07afa60af279d8c5ad-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c9b3f1cba08e4b07afa60af279d8c5ad-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c9b3f1cba08e4b07afa60af279d8c5ad-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c9b3f1cba08e4b07afa60af279d8c5ad-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "question = \"Which parts does a film have?\"\n",
    "\n",
    "parse = nlp(question)\n",
    "\n",
    "displacy.render(parse, jupyter=True, style=\"ent\")\n",
    "\n",
    "displacy.render(parse, jupyter=True, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4\n",
    "\n",
    "- \"Who/What was/is/were (the) X of Y?\" [What is the country of origin of Black Mirror?]\n",
    "- \"Y was/is/were X by whom/what?\" [Inception was directed by whom?]\n",
    "- \"Who/What X Y?\" [Who directed The Shawshank Redemption?]\n",
    "- \"Which movies are X by Y?\" [Which movies are directed by Alice Wu?]\n",
    "- \"When did Y X?\" [When did Alan Rickman die?]\n",
    "- \"By whom/what was/is/were Y X?\" [By whom was Tarzan directed?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\") # this loads the model for analysing English text\n",
    "\n",
    "def getPropertyAndEntity(parse) :\n",
    "    propRange = []\n",
    "    prop = \"\"\n",
    "    entityRange = [] \n",
    "    for i in range(len(parse)) : # iterate over the token objects \n",
    "        word = parse[i]\n",
    "    \n",
    "        if word.dep_ == \"ROOT\" and word.lemma_ != \"be\":\n",
    "            # Set root as property when it isn't a form of to be\n",
    "            prop = word.text\n",
    "    \n",
    "        if word.text.istitle():\n",
    "            # Check if word starts with uppercase letter for entities\n",
    "            if i != 0 or (word.pos_ != \"PRON\" and word.pos_ != \"DET\" and word.pos_ != \"ADV\" and word.pos_ != \"ADP\"):\n",
    "                # If it isn't one of the question words (Who/What/Which/When)\n",
    "                entityRange.append(i)\n",
    "        elif word.pos_ == \"NOUN\" or word.pos_ == \"VERB\":\n",
    "            # Properties are nouns or verbs\n",
    "            previousWord = parse[i-1]\n",
    "            if previousWord.pos_ == \"ADJ\" :\n",
    "                # Also add adjectives of the properties\n",
    "                propRange.append(i-1)\n",
    "            propRange.append(i)\n",
    "\n",
    "    if prop == \"\":\n",
    "        minProp = propRange[0]\n",
    "        maxProp = propRange[len(propRange)-1]\n",
    "        prop = parse[minProp:maxProp+1].lemma_\n",
    "\n",
    "    minEntity = entityRange[0]\n",
    "    maxEntity = entityRange[len(entityRange)-1]\n",
    "    entity = parse[minEntity:maxEntity+1].text\n",
    "    return prop, entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def findEntityID(entity) :\n",
    "    entityID = []\n",
    "    url = 'https://www.wikidata.org/w/api.php'\n",
    "    params = {'action':'wbsearchentities',\n",
    "              'language':'en',\n",
    "              'format':'json',\n",
    "              'search':entity}\n",
    "    json = requests.get(url,params).json()\n",
    "    for result in json['search']:\n",
    "        entityID.append(result['id'])\n",
    "    return entityID\n",
    "        \n",
    "def findPropertyID(prop) :\n",
    "    propID = []\n",
    "    url = 'https://www.wikidata.org/w/api.php'\n",
    "    params = {'action':'wbsearchentities',\n",
    "              'type': 'property',\n",
    "              'language':'en',\n",
    "              'format':'json',\n",
    "              'search':prop}\n",
    "    json = requests.get(url,params).json()\n",
    "    for result in json['search']:\n",
    "        propID.append(result['id'])\n",
    "    return propID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Get answer to query\n",
    "def answerQuery(query) : \n",
    "    answer = []\n",
    "    url = 'https://query.wikidata.org/sparql'\n",
    "    results = requests.get(url, params={'query': query, 'format': 'json'}).json()\n",
    "    \n",
    "    try:\n",
    "        answer.append(results['boolean'])\n",
    "    except:\n",
    "        for item in results['results']['bindings']:\n",
    "            for var in item :\n",
    "                answer.append(item[var]['value'])\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnswer(propID, entityID) :\n",
    "    answer = []\n",
    "    # Try every combination of property and entity untill an answer is given\n",
    "    for i in range(len(propID)) :\n",
    "        for j in range(len(entityID)) :\n",
    "            entity = entityID[j]\n",
    "            prop = propID[i]\n",
    "            \n",
    "            # Construct the query\n",
    "            query = 'SELECT ?answerLabel WHERE { wd:' + entity + ' wdt:' + prop + ''' ?answer . SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" . } }'''\n",
    "            # Construct the opposite query\n",
    "            query2 = 'SELECT ?answerLabel WHERE { ?answer wdt:' + prop + ' wd:' + entity + ''' . SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" . } }'''\n",
    "            \n",
    "            # Get the answer to the question\n",
    "            answer = answerQuery(query)\n",
    "            if answer != [] :\n",
    "                return answer\n",
    "            \n",
    "            # Try to get the answer when using the opposite query\n",
    "            answer = answerQuery(query2)\n",
    "            if answer != [] :\n",
    "                return answer\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answerQuestion(question) :\n",
    "    # Parse question\n",
    "    parse = nlp(question)\n",
    "    \n",
    "    # Get the property and entity\n",
    "    prop, entity = getPropertyAndEntity(parse)\n",
    "    #print(\"prop:\", prop)\n",
    "    #print(\"entity:\", entity)\n",
    "    \n",
    "    # Find the entity id from wikidata\n",
    "    entityID = findEntityID(entity)\n",
    "        \n",
    "    # Find the property id from wikidata\n",
    "    propID = findPropertyID(prop)\n",
    "    \n",
    "    # Get the answer to the question\n",
    "    answer = getAnswer(propID, entityID)\n",
    "                \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please ask a question\n",
      "\"Inception was directed by whom?\"\n",
      "['Christopher Nolan']\n"
     ]
    }
   ],
   "source": [
    "# Test question from input\n",
    "question = input('Please ask a question\\n')\n",
    "answer = answerQuestion(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By whom was Tarzan directed?\n",
      "['Chris Buck', 'Kevin Lima']\n"
     ]
    }
   ],
   "source": [
    "# 10 questions that the function can answer\n",
    "questions = [\n",
    "    \"Inception was directed by whom?\",\n",
    "    \"Who directed The Shawshank Redemption?\",\n",
    "    \"What is the country of origin of Black Mirror?\",\n",
    "    \"Which movies are directed by Alice Wu?\",\n",
    "    \"When did Alan Rickman die?\",\n",
    "    \"Who is the composer of Lord of The Rings?\",\n",
    "    \"Which movies did Christopher Nolan direct?\",\n",
    "    \"What seasons does Twin Peaks have?\",\n",
    "    \"When was Morgan Freeman born?\",\n",
    "    \"By whom was Tarzan directed?\"\n",
    "]\n",
    "\n",
    "index = 9\n",
    "print(questions[index])\n",
    "answer = answerQuestion(questions[index])\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
